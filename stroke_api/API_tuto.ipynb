{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b9227f7",
   "metadata": {},
   "source": [
    "# Mise à disposition du jeu de données stroke_dataset via une API REST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02037c20",
   "metadata": {},
   "source": [
    "## Description du dataset\n",
    "\n",
    "Le jeu de données utilisé provient de Kaggle : [Stroke Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset).  \n",
    "Il contient des données de patients avec différentes caractéristiques médicales et sociales, ainsi que l'information si le patient a subi un accident vasculaire cérébral (AVC) ou non.\n",
    "\n",
    "Télécharger les données et ajouter les dans un dossier data/.\n",
    "\n",
    "Les colonnes des données sont :  \n",
    "- `id` : Identifiant unique du patient  \n",
    "- `gender` : Sexe  \n",
    "- `age` : Âge  \n",
    "- `hypertension` : Présence d'hypertension (0 ou 1)  \n",
    "- `heart_disease` : Présence de maladie cardiaque (0 ou 1)  \n",
    "- `ever_married` : Statut marital  \n",
    "- `work_type` : Type d'emploi  \n",
    "- `Residence_type` : Urbaine ou rurale  \n",
    "- `avg_glucose_level` : Moyenne du taux de glucose  \n",
    "- `bmi` : Indice de masse corporelle  \n",
    "- `smoking_status` : Statut tabagique  \n",
    "- `stroke` : Présence d'AVC (0 ou 1)\n",
    "\n",
    "## Projet\n",
    "\n",
    "Vous devez exposer les données patients du jeu de données via une API REST afin que les données soit utilisables par d'autres équipes (médecins, data science, étude, etc.).\n",
    "\n",
    "Cette API REST sera développée avec FastAPI et les spécifications sont les suivantes :\n",
    "| Méthode | Endpoint                                      | Fonctionnalité                                                                                                    |\n",
    "| ------- | --------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- |\n",
    "| `GET`   | `/patients/{id}`                              | Récupère les détails d’un patient donné (via son identifiant unique)                                              |\n",
    "| `GET`   | `/patients?stroke=1&gender=Female&max_age=60` | Renvoie les patients filtrés selon plusieurs critères : AVC (oui/non), genre, âge maximal                         |\n",
    "| `GET`   | `/stats/`                                     | Fournit des statistiques agrégées sur les patients (ex. : nb total de patients, âge moyen, taux d’AVC, répartition hommes/femmes, etc.) |\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Quelques définitions\n",
    "\n",
    "\n",
    "1. Qu’est-ce qu’une API REST ?\n",
    "\n",
    "- API signifie Application Programming Interface (Interface de Programmation d’Application). C’est un ensemble de règles et de protocoles qui permettent à des logiciels de communiquer entre eux.\n",
    "- REST signifie Representational State Transfer. C’est un style architectural pour concevoir des services web.\n",
    "Il en existe d'autres mais REST est celui que vous rencontrerez le plus souvent.\n",
    "- Vous avez utilisé une API REST via l'API Google Books.\n",
    "\n",
    "- A quoi sert une API REST ?\n",
    "\n",
    "    - Permet à différentes applications de communiquer facilement, même si elles sont écrites dans des langages différents.\n",
    "    - Permet d’accéder à des services distants (ex : bases de données, services web) de manière standardisée.\n",
    "    - Facilite la création d’applications modulaires et évolutives (front-end, back-end, mobile, etc.)\n",
    "\n",
    "2. Principes clés d’une API REST\n",
    "\n",
    "- a. Utilisation du protocole HTTP\n",
    "Les échanges entre client et serveur utilisent des méthodes HTTP standard comme :\n",
    "\n",
    "    - GET : pour récupérer des données\n",
    "    - POST : pour envoyer ou créer des données\n",
    "    - PUT : pour mettre à jour des données\n",
    "    - DELETE : pour supprimer des données\n",
    "\n",
    "- b. Accès aux ressources via des URLs\n",
    "\n",
    "Chaque ressource (par exemple un livre, un utilisateur) est accessible via une URL unique.\n",
    "\n",
    "Exemple fictif:\n",
    "    https://api.example.com/books/123 pour accéder au livre d’identifiant 123.\n",
    "\n",
    "- c. Stateless (sans état)\n",
    "\n",
    "Le serveur ne conserve aucune information sur le client entre deux requêtes. Chaque requête doit contenir toutes les informations nécessaires.\n",
    "\n",
    "- d. Représentations des données\n",
    "\n",
    "Les données sont envoyées et reçues généralement en format JSON ou XML, qui sont faciles à lire et à manipuler.\n",
    "\n",
    "- e. Utilisation de codes status HTTP\n",
    "\n",
    "Chaque réponse du serveur est accompagnée d’un code HTTP indiquant le résultat de la requête. (cf [liste des codes](https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Status))\n",
    "\n",
    "## Outils utilisés\n",
    "1. FastAPI\n",
    "\n",
    "FastAPI est un framework Python moderne, rapide et très utilisé dans le milieu professionnel pour construire des API REST. \n",
    "\n",
    "Il permet :\n",
    "- une définition simple des routes et des paramètres  \n",
    "- La génération automatique de documentation interactive (Swagger UI)  \n",
    "- FastAPI lit les requêtes entrantes, les traite avec ton code Python, et retourne une réponse HTTP (en JSON).\n",
    "\n",
    "2. Uvicorn : exécute l'application FastAPI\n",
    "\n",
    "- Uvicorn est un serveur ASGI (Asynchronous Server Gateway Interface) : c'est une interface standard pour gérer les requêtes de manière asynchrone et performante, notamment utile pour les applications modernes.\n",
    "- Il attend les requêtes HTTP (par exemple depuis un navigateur), les transmet à FastAPI, et renvoie la réponse.\n",
    "- Uvicorn permet à l'API de fonctionner : sans Uvicorn ou un autre serveur, FastAPI ne peut pas fonctionner.\n",
    "\n",
    "\n",
    "3. Swagger UI : l’interface de doc et test interactive\n",
    "\n",
    "- Swagger UI est généré automatiquement par FastAPI.\n",
    "- C’est une interface web qui permet de :\n",
    "    - Voir toutes les routes disponibles dans l'API\n",
    "    - Tester les routes en envoyant des requêtes sans écrire de code (bouton try it out)\n",
    "    - Voir les paramètres attendus et les formats de réponse\n",
    "    \n",
    "4. Résumé des interactions\n",
    "\n",
    "- Tester la route de base de l'API grâce à la commande :\n",
    "```bash\n",
    "    poetry run fastapi dev stroke_api/main.py\n",
    "```\n",
    "\n",
    "--> Qu'est-ce qu'il se passe derrière cette commande ?\n",
    "\n",
    "- Uvicorn démarre un serveur local\n",
    "- FastAPI génère automatiquement une interface : Swagger UI, accessible sur http://127.0.0.1:8000/docs qui affiche toutes les routes définies dans le code python FastAPI\n",
    "- Quand on clique sur \"Try it out\" dans Swagger UI, Swagger envoie une requête HTTP au serveur (ici Uvicorn)\n",
    "- Le serveur (Uvicorn) la reçoit, l’envoie à FastAPI, qui traite et renvoie une réponse\n",
    "- Swagger UI affiche la réponse de l’API (par ex : liste de patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02e38a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Import des bibliothèques utiles au projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "548f6eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cf9064",
   "metadata": {},
   "source": [
    "## 1. Prétraitement des données / Data preprocessing\n",
    "\n",
    "Les données réelles sont rarement prêtes à être utilisées directement. Elles peuvent contenir des erreurs, des valeurs manquantes, des doublons, des formats incohérents, ou ne pas être adaptées au modèle ou au système cible.\n",
    "\n",
    "Le prétraitement consiste à nettoyer, structurer et transformer les données brutes avant de les exploiter dans un projet (modèle IA, API, visualisation, etc.).\n",
    "\n",
    "Vous avez déjà prétraité des données, petit rappel des éléments sur lesquels travailler dans un prétraitment classique et les méthodes pandas qu'il est possible d'utiliser pour les différentes étapes (des exeples d'utilisation des méthodes pandas sont disponibles dans la doc) : \n",
    "- explorer les données pour identifier les types de données, valeurs manquantes, incohérence ([info](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html), [dtypes](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dtypes.html))\n",
    "- adapter les types si nécessaire ([astypes](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html))\n",
    "- identifier les doublons et les supprimer s'il y en a ([duplicated](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html), [drop_duplicates](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html))\n",
    "- traiter les valeurs manquantes s'il y en a ([fillna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html), [dropna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html), [replace](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html))\n",
    "- identifier les incohérences éventuelles (valeurs aberrantes/outliers) en vérifiant si les valeurs min, max, moyennes sont raisonnables (recherche internet si nécessaire) ([describe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html)), et les traiter.\n",
    "- Traiter les valeurs aberrantes si vous en détectez ([loc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) pour récupérer les lignes qui répondent à une certaine condition, cf exemple ci-dessous)\n",
    "\n",
    "\n",
    "**Exemple df.loc :**\n",
    "\n",
    "Récupérer toutes les lignes de df telles que la valeur de \"nom de colonne\" >= 0\n",
    "\n",
    "```df_subset = df.loc[stroke_data_df['nom de colonne'] >= 0]```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb65710",
   "metadata": {},
   "source": [
    "---\n",
    "### **TODO**\n",
    "1.a. Prétraiter les données du dataset.\n",
    "\n",
    "\n",
    "1.b. Documenter dans le README.md :\n",
    "- Les étapes de prétraitement,\n",
    "- Justification des choix concernant le traitement des valeurs manquantes (si besoin),\n",
    "- Liste des valeurs raisonnables utilisées pour détecter les valeurs aberrantes, \n",
    "- Justification des choix pour traiter les valeurs aberrantes (si besoin).\n",
    "\n",
    "2.a. Chercher des infos sur le format de fichier parquet et indiquer les sources consultées : \n",
    "- Différence principale avec le format csv ?\n",
    "- Dans quels cas l'utiliser ? \n",
    "- Pourquoi c'est un format adapté aux gros volumes de données ?\n",
    "\n",
    "\n",
    "\n",
    "2.b. Sauvegarder les données prétraiteées dans un fichier parquet ([to_parquet](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_parquet.html)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b391b2",
   "metadata": {},
   "source": [
    "### Prétraitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f760f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  gender   age  hypertension  heart_disease ever_married  \\\n",
      "0    9046    Male  67.0             0              1          Yes   \n",
      "1   51676  Female  61.0             0              0          Yes   \n",
      "2   31112    Male  80.0             0              1          Yes   \n",
      "3   60182  Female  49.0             0              0          Yes   \n",
      "4    1665  Female  79.0             1              0          Yes   \n",
      "5   56669    Male  81.0             0              0          Yes   \n",
      "6   53882    Male  74.0             1              1          Yes   \n",
      "7   10434  Female  69.0             0              0           No   \n",
      "8   27419  Female  59.0             0              0          Yes   \n",
      "9   60491  Female  78.0             0              0          Yes   \n",
      "10  12109  Female  81.0             1              0          Yes   \n",
      "11  12095  Female  61.0             0              1          Yes   \n",
      "12  12175  Female  54.0             0              0          Yes   \n",
      "13   8213    Male  78.0             0              1          Yes   \n",
      "14   5317  Female  79.0             0              1          Yes   \n",
      "15  58202  Female  50.0             1              0          Yes   \n",
      "16  56112    Male  64.0             0              1          Yes   \n",
      "17  34120    Male  75.0             1              0          Yes   \n",
      "18  27458  Female  60.0             0              0           No   \n",
      "19  25226    Male  57.0             0              1           No   \n",
      "\n",
      "        work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
      "0         Private          Urban             228.69  36.6  formerly smoked   \n",
      "1   Self-employed          Rural             202.21   NaN     never smoked   \n",
      "2         Private          Rural             105.92  32.5     never smoked   \n",
      "3         Private          Urban             171.23  34.4           smokes   \n",
      "4   Self-employed          Rural             174.12  24.0     never smoked   \n",
      "5         Private          Urban             186.21  29.0  formerly smoked   \n",
      "6         Private          Rural              70.09  27.4     never smoked   \n",
      "7         Private          Urban              94.39  22.8     never smoked   \n",
      "8         Private          Rural              76.15   NaN          Unknown   \n",
      "9         Private          Urban              58.57  24.2          Unknown   \n",
      "10        Private          Rural              80.43  29.7     never smoked   \n",
      "11       Govt_job          Rural             120.46  36.8           smokes   \n",
      "12        Private          Urban             104.51  27.3           smokes   \n",
      "13        Private          Urban             219.84   NaN          Unknown   \n",
      "14        Private          Urban             214.09  28.2     never smoked   \n",
      "15  Self-employed          Rural             167.41  30.9     never smoked   \n",
      "16        Private          Urban             191.61  37.5           smokes   \n",
      "17        Private          Urban             221.29  25.8           smokes   \n",
      "18        Private          Urban              89.22  37.8     never smoked   \n",
      "19       Govt_job          Urban             217.08   NaN          Unknown   \n",
      "\n",
      "    stroke  \n",
      "0        1  \n",
      "1        1  \n",
      "2        1  \n",
      "3        1  \n",
      "4        1  \n",
      "5        1  \n",
      "6        1  \n",
      "7        1  \n",
      "8        1  \n",
      "9        1  \n",
      "10       1  \n",
      "11       1  \n",
      "12       1  \n",
      "13       1  \n",
      "14       1  \n",
      "15       1  \n",
      "16       1  \n",
      "17       1  \n",
      "18       1  \n",
      "19       1  \n"
     ]
    }
   ],
   "source": [
    "# Importation des données\n",
    "try:\n",
    "\tdf = pd.read_csv('../data/healthcare-dataset-stroke-data.csv') # on importe le fichier CSV dans un dataframe\n",
    "\tprint(df.head(20))  # on affiche les 20 premières lignes du dataframe\n",
    "except FileNotFoundError: # Gestion de l'erreur si le fichier n'est pas trouvé\n",
    "\tprint(\"Le fichier '../data/healthcare-dataset-stroke-data.csv' est introuvable. Veuillez le télécharger depuis Kaggle et le placer dans le dossier 'data/'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b658c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 5110 non-null   int64  \n",
      " 1   gender             5110 non-null   object \n",
      " 2   age                5110 non-null   float64\n",
      " 3   hypertension       5110 non-null   int64  \n",
      " 4   heart_disease      5110 non-null   int64  \n",
      " 5   ever_married       5110 non-null   object \n",
      " 6   work_type          5110 non-null   object \n",
      " 7   Residence_type     5110 non-null   object \n",
      " 8   avg_glucose_level  5110 non-null   float64\n",
      " 9   bmi                4909 non-null   float64\n",
      " 10  smoking_status     5110 non-null   object \n",
      " 11  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 479.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# On affiche les informations du dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be78697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de doublons : 0\n"
     ]
    }
   ],
   "source": [
    "# On vérifie s'il y a des doublons dans le dataframe et on les supprimes\n",
    "df_duplicated = df.duplicated()\n",
    "print(f\"Nombre de doublons : {df_duplicated.sum()}\")\n",
    "\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92868785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de valeurs manquantes dans la colonne 'bmi' : 201\n"
     ]
    }
   ],
   "source": [
    "# On calcul le nombre de valeurs manquantes dans la colonne 'bmi'\n",
    "df_bmi = df['bmi'].isnull().sum()\n",
    "print(f\"Nombre de valeurs manquantes dans la colonne 'bmi' : {df_bmi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110e8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender  age    Residence_type  work_type    \n",
      "Female  0.08   Urban           children         14.100\n",
      "        0.32   Rural           children         16.100\n",
      "               Urban           children         19.600\n",
      "        0.40   Rural           children         17.400\n",
      "        0.48   Rural           children         16.100\n",
      "                                                 ...  \n",
      "Male    82.00  Rural           Self-employed    26.080\n",
      "               Urban           Govt_job         29.000\n",
      "                               Private          29.525\n",
      "                               Self-employed    25.360\n",
      "Other   26.00  Rural           Private          22.400\n",
      "Name: bmi, Length: 881, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# On calcule et affiche la moyenne pour 'bmi'\n",
    "print(df.groupby(['gender', 'age', 'Residence_type', 'work_type'])['bmi'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437dfa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       36.6\n",
      "1       26.8\n",
      "2       32.5\n",
      "3       34.4\n",
      "4       24.0\n",
      "        ... \n",
      "5105    29.7\n",
      "5106    40.0\n",
      "5107    30.6\n",
      "5108    25.6\n",
      "5109    26.2\n",
      "Name: bmi, Length: 5110, dtype: float64\n",
      "----------------9----------------\n"
     ]
    }
   ],
   "source": [
    "# On applique la moyenne pour les 'bmi' avec NaN\n",
    "df['bmi'] = df.groupby(['gender', 'age', 'Residence_type', 'work_type'])['bmi'].transform(lambda x: round(x.fillna(x.mean()), 1))\n",
    "print(df['bmi'])\n",
    "\n",
    "bmi = df['bmi'].isnull().sum()\n",
    "print(f\"----------------{bmi}----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb91a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       36.6\n",
      "1       26.8\n",
      "2       32.5\n",
      "3       34.4\n",
      "4       24.0\n",
      "        ... \n",
      "5105    29.7\n",
      "5106    40.0\n",
      "5107    30.6\n",
      "5108    25.6\n",
      "5109    26.2\n",
      "Name: bmi, Length: 5110, dtype: float64\n",
      "----------------0----------------\n"
     ]
    }
   ],
   "source": [
    "# On applique une autre moyenne moins restrictive pour les valeurs qui n'ont pas reçu la précédente moyenne 'bmi'\n",
    "df['bmi'] = df.groupby(['gender', 'work_type'])['bmi'].transform(lambda x: round(x.fillna(x.mean()), 1))\n",
    "print(df['bmi'])\n",
    "\n",
    "bmi = df['bmi'].isnull().sum()\n",
    "print(f\"----------------{bmi}----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db92d6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, gender, age, hypertension, heart_disease, ever_married, work_type, Residence_type, avg_glucose_level, bmi, smoking_status, stroke]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Vérification valeurs aberrantes sur le glucose\n",
    "if 'avg_glucose_level' in df.columns:\n",
    "    df_glucose = df.loc[(df['avg_glucose_level'] < 50) | (df['avg_glucose_level'] > 280)]\n",
    "    print(df_glucose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2493f7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  gender   age  hypertension  heart_disease ever_married work_type  \\\n",
      "928   41097  Female  23.0             1              0           No   Private   \n",
      "2128  56420    Male  17.0             1              0           No  children   \n",
      "4209  51856    Male  38.0             1              0          Yes   Private   \n",
      "\n",
      "     Residence_type  avg_glucose_level   bmi smoking_status  stroke  \n",
      "928           Urban              70.03  78.0         smokes       0  \n",
      "2128          Rural              61.67  97.6   never smoked       0  \n",
      "4209          Rural              56.90  92.0   never smoked       0  \n"
     ]
    }
   ],
   "source": [
    "# Vérification valeurs aberrantes sur le bmi\n",
    "if 'bmi' in df.columns:\n",
    "    df_bmi = df.loc[(df['bmi'] < 10) | (df['bmi'] > 75)]\n",
    "    print(df_bmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa71398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour détecter les valeurs aberrantes dans le dataframe\n",
    "def aberrante_values(df):\n",
    "    \"\"\"\n",
    "    Fonction pour détecter les valeurs aberrantes dans le dataframe.\n",
    "    Cette fonction vérifie si la colonne 'work_type' est présente et si l'âge est inférieur à 18 ans.\n",
    "    Si c'est le cas, elle remplace la valeur de 'work_type' par 'children' si l'âge est inférieur à 18 ans et que 'work_type' n'est pas 'children'.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Le dataframe à analyser.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Le dataframe avec les valeurs aberrantes traitées.\"\"\"\n",
    "    \n",
    "    if 'work_type' in df.columns and 'age' in df.columns:\n",
    "        df.loc[(df['age'] < 18) & (df['work_type'] != 'children'), 'work_type'] = 'children'\n",
    "    \n",
    "    if 'smoking_status' in df.columns and 'age' in df.columns:\n",
    "        df.loc[(df['age'] < 18) & (df['smoking_status'] == 'Unknown'), 'smoking_status'] = 'never smoked'\n",
    "        df.loc[(df['age'] >= 18) & (df['smoking_status'] == 'Unknown'), 'smoking_status'] = 'not specified'\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = aberrante_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dfaae1",
   "metadata": {},
   "source": [
    "-----\n",
    "## Développement de l'API\n",
    "\n",
    "A présent que les données sont propres, on peut débuter la création de l'API.\n",
    "\n",
    "Pour cela, vous allez avoir besoin de quelques fonctions permettant de filtrer les données.\n",
    "\n",
    "Vous allez les définir ci-dessous, ce qui vous permettra de les tester puis les fonctions seront reportées dans le fichier filters.py."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c2b0d0",
   "metadata": {},
   "source": [
    "## Route `/patients/`\n",
    "- Cette route retourne une liste filtrée de patients\n",
    "- On souhaite pouvoir filtrer par `gender`, `stroke` ou `max_age`\n",
    "\n",
    "L'objectif est ici de définir une fonction python qui prend en entrée les paramètres optionnels : _gender_, *stroke*, *max_age* et qui renvoie un dictionnaire filtré des données.\n",
    "\n",
    "On décompose la rédaction de cette fonction en plusieurs étapes. \n",
    "\n",
    "Dans un premier temps, écrire et tester les filtres que l'on souhaite appliquer sur les données (utiliser [loc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b25d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer le dataframe pour ne garder que les patients pour lesquels \"stroke=1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eca4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les données pour ne garder que les patients pour lesquels \"gender=\"male\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bac1cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les données pour ne garder que les patients tels que \"age <= max_age\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f1928",
   "metadata": {},
   "source": [
    "Appliquer successivement les 3 filtres au sein d'une fonction qui prend en entrée le dataframe, _stroke_, _gender_, _max_age_ et qui renvoie une liste de dictionnaire de patients (utiliser la méthode pandas [to_dict](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_dict.html)).\n",
    "\n",
    "Exemple\n",
    "```\n",
    "[{'id': 9046,\n",
    "  'gender': 'Male',\n",
    "  'age': 67.0,\n",
    "  ...\n",
    "  'smoking_status': 'formerly smoked',\n",
    "  'stroke': 1},\n",
    " {'id': 31112,\n",
    "  'gender': 'Male',\n",
    "  'age': 80.0,\n",
    "  ...\n",
    "  'smoking_status': 'formerly smoked',\n",
    "  'stroke': 1}]\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c364a35",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (851164598.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef filter_patient(df, max_age, gender, stroke):\u001b[39m\n                                                    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def filter_patient(df, max_age, gender, stroke):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85017c8f",
   "metadata": {},
   "source": [
    "A présent on souhaite ajouter des informations sur les types des paramètres et valeurs de retour de la fonction pour faciliter sa compréhension et son utilisation, ce qu’on appelle l’annotation de type (type hinting).\n",
    "\n",
    "Cette pratique facilite la lecture et la maintenance du code.\n",
    "\n",
    "Quels changements pour la fonction ?\n",
    "\n",
    "A la suite de chaque paramètre, on ajoute le type attendu pour le paramètre. À la suite des paramètres on ajoute le type de ce que qui est retourné par la fonction, dans l'exemple ici : \n",
    "\n",
    "```def filter_patient(stroke_data_df: pd.DataFrame, gender: str, etc) -> list[dict]```\n",
    "\n",
    "Ajouter les types dans la définition de la fonction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b7f0a",
   "metadata": {},
   "source": [
    "Tester la fonction en ne mettant pas de valeur pour *max_age*.\n",
    "\n",
    "Que se passe-t-il ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78da71a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "956bca5f",
   "metadata": {},
   "source": [
    "Dans la fonction écrite ci-dessus, chaque paramètre est obligatoire. \n",
    "\n",
    "On souhaite pouvoir filtrer les patients sur 0, 1 ou 2 des paramètres de la fonction (filtrer seulement sur *max_age*  mais ne pas appliquer de filtres sur _gender_ et _stroke_ par exemple).\n",
    "\n",
    "On peut rendre optionnel les paramètres d'un fonction en choisissant une valeur par défault. Si on utilise la fonction en n'utilisant pas ces paramètres alors la valeur par défault est utilisé.\n",
    "\n",
    "Copier coller votre fonction ci-dessous et ajouter en paramètre : `max_age=None`\n",
    "\n",
    "et ajouter la condition suivante **avant le filtre** sur `max_age` : \n",
    "\n",
    "```if max_age is not None : ``` \n",
    "\n",
    "Si la fonction _filter_patient_ est appelée sans argument *max_age*, alors le filtre sur *max_age* n'est pas appliqué. \n",
    "\n",
    "Il est tout à fait possible de définir une valeur par défault par exemple 30 ans : dans ce cas si la fonction est appelée sans argument *max_age*, alors par défault on filtre les patients ayant moins de 30 ans.\n",
    "\n",
    "**ATTENTION :** Les paramètres optionnels doivent toujours être à la fin de la liste de paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f987b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction filter_patient paramètre max_age optionnel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23084a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test fonction sans argument max_age\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe7f5de",
   "metadata": {},
   "source": [
    "Ajouter des valeurs par défault et les conditions pour chaque filtre.\n",
    "\n",
    "Pour les types, on indique qu'il s'agit de paramètres optionels en utilisant le module python _typing_\n",
    "\n",
    "```\n",
    "from typing import Optional\n",
    "def filter_patient(stroke_data_df: pd.DataFrame, gender: Optional[str] = None,etc)\n",
    "```\n",
    "\n",
    "Adapter les types en utilisant ce modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db8ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction avec ajout de paramètres par défault et de type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c073eb",
   "metadata": {},
   "source": [
    "Tester la fonction sans argument pour les filtres, elle doit donc renvoyer le dataframe non filtré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ffbfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test fonction sans argument pour les filtres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7816b86",
   "metadata": {},
   "source": [
    "Cette fonction va être utilisée dans la définition de l'API pour créer une route qui permette d'accéder à des données filtrées sur les patients.\n",
    "\n",
    "Dans le fichier de définition de l'API, toutes les fonctions vont travailler sur les données du fichier. \n",
    "\n",
    "Pour alléger les fonctions on va donc utiliser une **variable globale** pour les données et supprimer le paramètre `df` de la fonction.\n",
    "\n",
    "On lit les données en début de fichier puis on travaille au sein des fonctions sur une copie du dataframe de données.\n",
    "\n",
    "\n",
    "**En résumé les modifications à faire sont :**\n",
    "\n",
    "\n",
    "- Supprimer le paramètre df de la fonction,\n",
    "- Ajouter en début de fonction :  \n",
    "```df = stroke_data_df.copy()```\n",
    "\n",
    "1. Dans le fichier filters.py, il suffit d'ajouter : \n",
    "- lecture du fichier de données prétraitée dans la variable *df* en début de fichier (utiliser pandas),\n",
    "- @app.get(\"/patients/\") pour définir le route,\n",
    "puis la fonction.\n",
    "\n",
    "2. Dans le fichier api.py: appeler la fonction dans la route correspondante.\n",
    "\n",
    "Tester la route avec \n",
    "\n",
    "```poetry run fastapi dev stroke_api/main.py```\n",
    "\n",
    "http://127.0.0.1:8000/docs : utiliser la fonctionnalité Try it out pour tester la route."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b80fee",
   "metadata": {},
   "source": [
    "---\n",
    "## Autres routes\n",
    "\n",
    "De la même manière, créer les fonctions appropriées pour la création de :\n",
    "- la route `/patients/{id}` : Récupère les détails d’un patient donné (via son identifiant unique) \n",
    "\n",
    "- la route `/stats/` : Fournit des statistiques agrégées sur les patients (ex. : nb total de patients, âge moyen, taux d’AVC, répartition hommes/femmes).\n",
    "\n",
    "- Lister les tâches à faire sous forme d'issue github : travailler sur une branche différentes pour l'ajout de chacune des routes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stroke-api-AzSXMV3o-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
